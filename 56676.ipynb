{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "56676.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmreiniger/datascience.stackexchange/blob/master/56676.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V16_MK183c51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d1a9d150-7907-4ed6-acbf-19b2097dfbea"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "n = 8\n",
        "\n",
        "# Create an input array of 50,000 samples of n random numbers each\n",
        "x = np.random.randint(0, 100, size=(50000, n))\n",
        "\n",
        "# And a one-hot encoded target denoting the index of the maximum of the inputs\n",
        "y = to_categorical(np.argmax(x, axis=1), num_classes=n)\n",
        "\n",
        "# Split into training and testing datasets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
        "\n",
        "print(x_train[:10])\n",
        "print(y_train[:10])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[55 85 52 55 65 70 18 35]\n",
            " [42 27 77 81 69 63 71  4]\n",
            " [15 54 86 88 40 74 60  7]\n",
            " [ 5 17 34 57  0 81 45 94]\n",
            " [ 5 36 34 68  6 95 40 40]\n",
            " [20 33 26  4  6 74 28 95]\n",
            " [72 38 67 22 78 98 37 65]\n",
            " [98 35  4  2 18 33 55 81]\n",
            " [22 12 22 77 98 96 92 30]\n",
            " [ 5 92 17 24 96 24  3 18]]\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8c-s_yDD3G-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "165ac3ff-1e26-4cc6-eca3-a18f7473d7ca"
      },
      "source": [
        "i = Input(shape=(n, ))\n",
        "a = Dense(int(n**2), activation='sigmoid')(i)\n",
        "o = Dense(n, activation='sigmoid')(a)\n",
        "\n",
        "model = Model(inputs=i, outputs=o)\n",
        "\n",
        "adam = Adam(lr=.01, decay=0.005)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=30, batch_size=8, validation_data=[x_test, y_test])\n",
        "\n",
        "print(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0803 21:44:44.864091 140080907765632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0803 21:44:44.914702 140080907765632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0803 21:44:44.925900 140080907765632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0803 21:44:44.979133 140080907765632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0803 21:44:44.993714 140080907765632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0803 21:44:45.136855 140080907765632 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0803 21:44:45.191799 140080907765632 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 37500 samples, validate on 12500 samples\n",
            "Epoch 1/30\n",
            "37500/37500 [==============================] - 6s 170us/step - loss: 0.6164 - val_loss: 0.5131\n",
            "Epoch 2/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.4854 - val_loss: 0.4717\n",
            "Epoch 3/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.4588 - val_loss: 0.4601\n",
            "Epoch 4/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.4437 - val_loss: 0.4488\n",
            "Epoch 5/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.4348 - val_loss: 0.4432\n",
            "Epoch 6/30\n",
            "37500/37500 [==============================] - 6s 150us/step - loss: 0.4275 - val_loss: 0.4403\n",
            "Epoch 7/30\n",
            "37500/37500 [==============================] - 6s 150us/step - loss: 0.4227 - val_loss: 0.4346\n",
            "Epoch 8/30\n",
            "37500/37500 [==============================] - 6s 154us/step - loss: 0.4180 - val_loss: 0.4317\n",
            "Epoch 9/30\n",
            "37500/37500 [==============================] - 6s 154us/step - loss: 0.4143 - val_loss: 0.4290\n",
            "Epoch 10/30\n",
            "37500/37500 [==============================] - 6s 154us/step - loss: 0.4115 - val_loss: 0.4260\n",
            "Epoch 11/30\n",
            "37500/37500 [==============================] - 6s 161us/step - loss: 0.4091 - val_loss: 0.4240\n",
            "Epoch 12/30\n",
            "37500/37500 [==============================] - 6s 165us/step - loss: 0.4066 - val_loss: 0.4221\n",
            "Epoch 13/30\n",
            "37500/37500 [==============================] - 6s 160us/step - loss: 0.4044 - val_loss: 0.4204\n",
            "Epoch 14/30\n",
            "37500/37500 [==============================] - 6s 156us/step - loss: 0.4027 - val_loss: 0.4192\n",
            "Epoch 15/30\n",
            "37500/37500 [==============================] - 6s 154us/step - loss: 0.4010 - val_loss: 0.4172\n",
            "Epoch 16/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.3994 - val_loss: 0.4161\n",
            "Epoch 17/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.3980 - val_loss: 0.4151\n",
            "Epoch 18/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3967 - val_loss: 0.4141\n",
            "Epoch 19/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3954 - val_loss: 0.4138\n",
            "Epoch 20/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.3943 - val_loss: 0.4128\n",
            "Epoch 21/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.3932 - val_loss: 0.4116\n",
            "Epoch 22/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3922 - val_loss: 0.4107\n",
            "Epoch 23/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3911 - val_loss: 0.4107\n",
            "Epoch 24/30\n",
            "37500/37500 [==============================] - 6s 152us/step - loss: 0.3905 - val_loss: 0.4090\n",
            "Epoch 25/30\n",
            "37500/37500 [==============================] - 6s 155us/step - loss: 0.3894 - val_loss: 0.4085\n",
            "Epoch 26/30\n",
            "37500/37500 [==============================] - 6s 154us/step - loss: 0.3887 - val_loss: 0.4079\n",
            "Epoch 27/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3880 - val_loss: 0.4072\n",
            "Epoch 28/30\n",
            "37500/37500 [==============================] - 6s 151us/step - loss: 0.3872 - val_loss: 0.4069\n",
            "Epoch 29/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3865 - val_loss: 0.4063\n",
            "Epoch 30/30\n",
            "37500/37500 [==============================] - 6s 153us/step - loss: 0.3859 - val_loss: 0.4057\n",
            "0.83792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzsLz-g7RtqG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6de79e4e-651b-4ced-c109-2995b8911f48"
      },
      "source": [
        "print(np.where(np.argmax(model.predict(x_test), axis=1) == np.argmax(y_test, axis=1), 1, 0).mean())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.83792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiotuDTETDM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faabc7a8-adc9-4ab8-df9f-26098afcb1fe"
      },
      "source": [
        "x_big = np.random.randint(100, 200, size=(1000, n))\n",
        "y_big = to_categorical(np.argmax(x_big, axis=1), num_classes=n)\n",
        "print(np.where(np.argmax(model.predict(x_big), axis=1) == np.argmax(y_big, axis=1), 1, 0).mean())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex3Wy3ya2cTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8f38d3d-377f-44a4-84ad-1e64b5b84ef7"
      },
      "source": [
        "# Now use inputs between +- 1\n",
        "x_new = (np.random.random(size=(50000, n)).reshape(50000,n) -0.5)*2\n",
        "y_new = to_categorical(np.argmax(x_new, axis=1), num_classes=n)\n",
        "x_new_train, x_new_test, y_new_train, y_new_test = train_test_split(x_new, y_new)\n",
        "\n",
        "i = Input(shape=(n, ))\n",
        "a = Dense(int(n**2), activation='sigmoid')(i)\n",
        "o = Dense(n, activation='sigmoid')(a)\n",
        "model = Model(inputs=i, outputs=o)\n",
        "\n",
        "adam = Adam(lr=.0003)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy')\n",
        "\n",
        "model.fit(x_new_train, y_new_train, epochs=30, batch_size=8, validation_data=[x_new_test, y_new_test])\n",
        "\n",
        "print(np.where(np.argmax(model.predict(x_new_test), axis=1) == np.argmax(y_new_test, axis=1), 1, 0).mean())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 02:48:32.465422 139816700307328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0804 02:48:32.502084 139816700307328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0804 02:48:32.511049 139816700307328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0804 02:48:32.557210 139816700307328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0804 02:48:32.571322 139816700307328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0804 02:48:32.698484 139816700307328 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0804 02:48:32.751286 139816700307328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 37500 samples, validate on 12500 samples\n",
            "Epoch 1/30\n",
            "37500/37500 [==============================] - 6s 163us/step - loss: 1.4861 - val_loss: 0.9815\n",
            "Epoch 2/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.7773 - val_loss: 0.6349\n",
            "Epoch 3/30\n",
            "37500/37500 [==============================] - 6s 150us/step - loss: 0.5636 - val_loss: 0.5023\n",
            "Epoch 4/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.4661 - val_loss: 0.4294\n",
            "Epoch 5/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.4084 - val_loss: 0.3838\n",
            "Epoch 6/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.3695 - val_loss: 0.3514\n",
            "Epoch 7/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.3408 - val_loss: 0.3261\n",
            "Epoch 8/30\n",
            "37500/37500 [==============================] - 5s 147us/step - loss: 0.3187 - val_loss: 0.3077\n",
            "Epoch 9/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.3008 - val_loss: 0.2904\n",
            "Epoch 10/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.2859 - val_loss: 0.2785\n",
            "Epoch 11/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.2736 - val_loss: 0.2666\n",
            "Epoch 12/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.2626 - val_loss: 0.2564\n",
            "Epoch 13/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.2531 - val_loss: 0.2479\n",
            "Epoch 14/30\n",
            "37500/37500 [==============================] - 6s 150us/step - loss: 0.2449 - val_loss: 0.2392\n",
            "Epoch 15/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.2370 - val_loss: 0.2324\n",
            "Epoch 16/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.2303 - val_loss: 0.2258\n",
            "Epoch 17/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.2241 - val_loss: 0.2204\n",
            "Epoch 18/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.2184 - val_loss: 0.2154\n",
            "Epoch 19/30\n",
            "37500/37500 [==============================] - 6s 147us/step - loss: 0.2132 - val_loss: 0.2100\n",
            "Epoch 20/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.2081 - val_loss: 0.2074\n",
            "Epoch 21/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.2039 - val_loss: 0.2021\n",
            "Epoch 22/30\n",
            "37500/37500 [==============================] - 6s 147us/step - loss: 0.1997 - val_loss: 0.1980\n",
            "Epoch 23/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.1958 - val_loss: 0.1932\n",
            "Epoch 24/30\n",
            "37500/37500 [==============================] - 6s 156us/step - loss: 0.1920 - val_loss: 0.1915\n",
            "Epoch 25/30\n",
            "37500/37500 [==============================] - 6s 158us/step - loss: 0.1886 - val_loss: 0.1887\n",
            "Epoch 26/30\n",
            "37500/37500 [==============================] - 6s 157us/step - loss: 0.1857 - val_loss: 0.1846\n",
            "Epoch 27/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.1825 - val_loss: 0.1814\n",
            "Epoch 28/30\n",
            "37500/37500 [==============================] - 6s 148us/step - loss: 0.1798 - val_loss: 0.1794\n",
            "Epoch 29/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.1770 - val_loss: 0.1779\n",
            "Epoch 30/30\n",
            "37500/37500 [==============================] - 6s 149us/step - loss: 0.1743 - val_loss: 0.1749\n",
            "0.96088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4J7ABXchtnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "39c2bb79-88ca-4285-fc5c-add8c395aefd"
      },
      "source": [
        "print(x_new_test[:10].round(2))\n",
        "print(model.predict(x_new_test[:10]).round(2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.45  0.32  0.12 -0.12  0.97 -0.23 -0.15 -0.12]\n",
            " [-0.97 -0.62  0.48  0.74  0.76 -0.67 -0.21  0.89]\n",
            " [-0.75 -0.95  0.39  0.94  0.67 -0.46 -0.05  0.31]\n",
            " [ 0.78 -0.98 -0.81  0.55 -0.27 -0.36  0.55 -0.84]\n",
            " [-0.57  0.29  0.49  0.65 -0.05 -0.83  0.83  0.87]\n",
            " [-0.56 -0.67 -0.12  0.38 -0.37  0.88  0.19 -0.94]\n",
            " [-0.26  0.25 -0.84 -0.6  -0.91 -0.68  0.52 -0.7 ]\n",
            " [ 0.62  0.08  0.84 -0.14  0.84  0.88  0.02  0.49]\n",
            " [-0.93  0.03  0.11 -0.01 -0.18 -0.09 -0.92  0.55]\n",
            " [ 0.32  0.7   1.    0.84  0.24  0.36 -0.32  0.07]]\n",
            "[[0.   0.   0.   0.   0.62 0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.02 0.   0.   0.   0.  ]\n",
            " [0.03 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.51 0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.16 0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1vbu0qYUBKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a73d906f-6512-4ea6-8ef1-29353d1cd98d"
      },
      "source": [
        "x_big = np.random.randint(100, 200, size=(1000, n))\n",
        "y_big = to_categorical(np.argmax(x_big, axis=1), num_classes=n)\n",
        "print(np.where(np.argmax(model.predict(x_big), axis=1) == np.argmax(y_big, axis=1), 1, 0).mean())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZB4R8jUUnfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgry49vBU3_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34c5050f-bbbf-4bef-8a0c-0ca7cf72c2f0"
      },
      "source": [
        "model.layers[1].get_weights()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.87956274,  1.1978772 ,  0.46450382,  0.7307273 , -0.6984442 ,\n",
              "         -1.3457828 ,  0.09478747,  1.0741805 , -1.507459  , -1.2638655 ,\n",
              "         -1.4725051 , -1.1914657 ,  1.8128251 , -0.6159663 , -1.0193957 ,\n",
              "         -1.6737666 , -2.066794  ,  1.4463797 , -1.0314105 , -0.9695291 ,\n",
              "         -0.8354103 , -2.0047107 ,  0.8812803 , -0.1561685 , -1.5060434 ,\n",
              "         -1.0683078 ,  1.3409086 , -1.385963  ,  1.1036689 ,  0.6200164 ,\n",
              "         -0.5659612 ,  1.8297471 , -1.8397077 , -0.5272667 ,  1.8492919 ,\n",
              "          0.49020806,  1.58267   ,  0.31083837, -1.6804259 ,  0.9360691 ,\n",
              "          1.4568046 , -0.38561386,  1.3096594 ,  1.060757  , -0.3548948 ,\n",
              "          1.2196922 , -1.7746696 , -1.3284345 , -2.433707  ,  1.5120528 ,\n",
              "         -0.76299334, -1.7531025 ,  0.02317628,  0.77569026, -1.7030356 ,\n",
              "          0.80639404,  0.18325688, -2.1653275 ,  0.8659146 , -1.796664  ,\n",
              "          1.807544  ,  1.438966  ,  1.1653038 ,  1.4669718 ],\n",
              "        [ 0.81185657, -1.9098729 ,  1.2062043 , -1.7157247 , -1.6518465 ,\n",
              "         -1.1600736 ,  0.28391016,  1.1471442 ,  0.72029704, -0.79943764,\n",
              "          1.6577171 ,  2.3563411 ,  1.7710721 ,  1.0918672 ,  1.0229312 ,\n",
              "         -0.6635257 ,  0.63841695, -0.02933835,  0.5245031 , -1.129405  ,\n",
              "         -2.401875  ,  0.3506382 , -1.9979991 , -1.52303   ,  1.3061223 ,\n",
              "         -2.0158155 , -0.8679447 , -0.3374607 , -1.7257581 , -2.0264292 ,\n",
              "          0.06900809, -1.5309936 ,  1.0567019 ,  0.43588513,  1.5359305 ,\n",
              "          0.700766  , -1.5650196 ,  0.67586774,  0.8691335 , -1.8643187 ,\n",
              "          0.7205838 ,  0.44369122,  1.7054312 ,  0.18644083,  1.7185191 ,\n",
              "         -0.57490784,  1.6586372 , -0.5302438 , -0.03726498, -0.02459898,\n",
              "          0.6032245 , -1.553938  ,  1.3988341 , -1.3633808 ,  1.5538739 ,\n",
              "          1.1924634 , -2.0161269 ,  0.4811328 ,  0.911937  , -0.4699615 ,\n",
              "          1.571363  , -0.45757183, -1.4738058 , -0.77236295],\n",
              "        [ 0.54255706,  1.4269772 , -1.888001  , -0.2839848 ,  0.01606112,\n",
              "          1.4624233 ,  1.3097986 ,  1.5493945 , -2.30356   , -1.3697702 ,\n",
              "         -0.23339239,  2.3208256 , -1.2119359 ,  0.12016452, -0.45636332,\n",
              "         -0.82191867, -0.5539657 ,  0.14103696,  0.85341513, -1.2138458 ,\n",
              "          0.30219758,  1.0080633 ,  0.3151738 ,  0.62264425,  0.7322352 ,\n",
              "         -0.16526394,  1.7281663 ,  0.15060028, -0.9917738 ,  0.58474386,\n",
              "          1.2560017 ,  0.5295882 ,  1.1170999 ,  1.1903644 , -1.0497936 ,\n",
              "         -1.8987474 ,  0.7619021 , -2.2875361 ,  0.80027723, -0.15873508,\n",
              "          0.22592758, -2.0112534 ,  0.33577305,  0.6969352 , -0.29353416,\n",
              "         -2.2363799 , -1.4599802 ,  1.9703733 ,  1.3208767 ,  1.7931561 ,\n",
              "         -2.2275465 ,  1.7435356 , -0.98111063, -0.0479908 ,  1.009027  ,\n",
              "         -1.3530912 ,  1.3277518 ,  0.19245562,  1.3366694 ,  1.5832882 ,\n",
              "         -1.9628772 , -0.7332719 , -2.3006701 ,  1.0216405 ],\n",
              "        [ 1.4642512 ,  1.2161973 , -1.4960388 , -1.4356451 ,  1.1383382 ,\n",
              "          0.61392975, -1.3217084 , -0.36871314,  0.75189215, -0.91414493,\n",
              "          1.2259283 , -0.48026133, -0.54837936, -0.9896549 , -1.8564755 ,\n",
              "          1.3847215 ,  1.6494917 , -2.2533002 ,  0.19036742,  1.1534952 ,\n",
              "          0.88461703, -0.03231214, -1.1540799 , -2.4448738 , -1.4212708 ,\n",
              "          1.2865033 , -1.6277633 , -0.53941876, -1.6015906 ,  1.1598343 ,\n",
              "         -0.6480084 ,  0.85239047,  1.2167553 , -1.2118706 ,  0.9635782 ,\n",
              "          0.31508398,  0.7427089 , -0.36142302,  1.1229211 ,  1.8901769 ,\n",
              "         -2.1543396 ,  1.2195766 , -1.5376015 , -1.9960898 , -0.3330292 ,\n",
              "         -1.7420305 ,  1.3099511 ,  0.9800758 , -0.64787644,  1.3983638 ,\n",
              "          0.9964658 ,  1.256105  ,  1.2781023 ,  0.09021375, -1.7201587 ,\n",
              "          1.5965576 ,  0.6552077 , -1.5134741 , -1.4665917 ,  1.3294493 ,\n",
              "          1.2846339 ,  1.343408  ,  1.3705226 ,  0.31671202],\n",
              "        [-2.0920823 , -1.7967346 , -1.8357879 ,  0.7597485 ,  1.8808894 ,\n",
              "         -1.9912081 ,  1.5704572 , -1.1593477 ,  1.1052161 ,  1.2893842 ,\n",
              "         -0.03807238, -1.4522973 , -0.9099802 , -0.02349343,  1.3334801 ,\n",
              "         -1.4026498 ,  1.0106168 ,  0.60701245, -1.8503016 ,  1.7122673 ,\n",
              "          0.2598166 ,  1.5639172 ,  1.2751783 ,  1.1874526 ,  0.146119  ,\n",
              "          0.12000217, -1.7189958 ,  1.6930356 , -0.91004807, -0.05488202,\n",
              "          1.3358712 , -0.67068315, -1.212998  ,  1.9004742 , -1.8218758 ,\n",
              "          1.3868157 , -1.8446276 ,  1.1072453 ,  0.7177509 , -0.43979615,\n",
              "         -1.2756706 , -1.1480544 ,  1.3185323 ,  0.07867216, -1.8470045 ,\n",
              "          1.460207  , -1.3869097 ,  0.06764038,  1.3965989 , -0.29173517,\n",
              "          1.0471904 ,  0.01339775, -1.1347238 , -1.7310215 , -1.0168921 ,\n",
              "          1.5279192 ,  1.8905367 , -0.46045187, -0.95861596, -1.3744676 ,\n",
              "          0.35766166,  1.6694543 , -0.8112865 ,  1.380926  ],\n",
              "        [ 0.8915862 , -0.6169825 ,  1.3130937 ,  1.4696975 , -1.1285104 ,\n",
              "         -0.84863204,  0.9533923 ,  0.2098775 ,  1.0607197 ,  2.241754  ,\n",
              "         -1.0451356 , -0.65335554, -1.1378477 , -1.9729779 ,  1.817674  ,\n",
              "          1.9746845 ,  1.1790539 ,  1.3382457 ,  1.6316454 , -0.16693646,\n",
              "          1.442921  ,  0.74552655, -1.8087927 ,  0.86689156, -1.5560586 ,\n",
              "         -1.2621199 ,  0.22748329,  0.01239029,  1.2678858 ,  0.41511378,\n",
              "         -1.7892442 , -1.2932998 , -0.29875743, -1.1890477 , -1.3301516 ,\n",
              "         -1.675533  ,  1.5841343 ,  1.1597205 , -2.4023185 ,  0.27274793,\n",
              "         -1.0923343 ,  1.6523424 , -1.7325404 ,  1.0357685 , -1.664682  ,\n",
              "          0.98870695, -0.14978857,  1.7773798 , -0.8809918 , -1.0602345 ,\n",
              "         -2.0001333 , -1.6728016 ,  0.6683434 , -1.0828688 ,  1.5897914 ,\n",
              "         -0.84245396, -0.88135785,  1.4326923 , -1.4458196 ,  1.4199986 ,\n",
              "         -0.93052506, -1.9140882 ,  0.6813574 , -0.16685571],\n",
              "        [-0.65303904, -1.0984311 ,  0.3884178 , -1.0763683 ,  1.4449774 ,\n",
              "          1.1425024 , -2.1387193 , -0.65176326,  0.35413626,  1.4274809 ,\n",
              "          1.3319191 , -0.2509321 ,  1.2008042 ,  1.3989264 , -1.1126105 ,\n",
              "         -0.23287351, -1.4202569 , -1.5934389 ,  1.6860592 ,  1.7765536 ,\n",
              "         -0.1635678 , -0.32794738,  1.0179824 ,  0.82429785,  1.7368151 ,\n",
              "          1.2971745 ,  1.4512223 , -1.9083838 ,  1.4666933 ,  1.1755977 ,\n",
              "          1.9187555 ,  0.9456885 , -1.7213068 ,  0.8483475 , -1.3072561 ,\n",
              "          1.4890237 ,  0.11813936, -1.8646483 , -0.92277855, -2.200512  ,\n",
              "          0.84486717,  1.1984681 , -1.8125224 ,  0.8861427 ,  0.63337153,\n",
              "          0.9667164 ,  0.539888  , -2.0518563 , -0.2177958 , -1.6921947 ,\n",
              "          1.0137321 ,  0.5631094 , -1.9384804 ,  1.5123585 ,  0.97810686,\n",
              "         -1.323578  , -1.9981245 , -0.33314338, -1.1381866 ,  0.39849108,\n",
              "         -1.3567921 , -0.26548588,  0.68686765, -2.001031  ],\n",
              "        [-1.8647287 ,  1.503077  ,  1.4813945 ,  1.3793092 , -0.9384961 ,\n",
              "          1.5269593 , -0.78833646, -2.178202  , -0.47122058, -0.87713015,\n",
              "         -1.7213862 , -0.7426071 , -1.1737084 ,  1.0739493 ,  0.15606233,\n",
              "          1.5923946 , -0.8056991 ,  0.23612113, -1.4931141 , -0.8358953 ,\n",
              "          0.70280963, -1.4581    ,  1.0929304 ,  0.4458615 ,  0.71145594,\n",
              "          1.6370165 , -0.82670546,  2.22131   ,  1.2079442 , -2.2166972 ,\n",
              "         -1.2022523 , -0.8310699 ,  1.7258354 , -1.7221644 ,  0.8033655 ,\n",
              "         -1.6416454 , -1.0829223 ,  1.3066137 ,  1.0108085 ,  0.9063934 ,\n",
              "          1.3831629 , -1.4670525 ,  0.27358216, -2.2314887 ,  1.8001177 ,\n",
              "          0.1764788 ,  1.2596295 , -0.5916527 ,  1.0526109 , -1.7213491 ,\n",
              "          0.65260684,  0.90953165,  0.6621986 ,  1.829161  , -1.0969406 ,\n",
              "         -1.8828179 ,  0.5380424 ,  1.8530273 ,  1.3821678 , -1.5263472 ,\n",
              "         -0.32966766, -0.29601833,  0.4729342 , -1.7246836 ]],\n",
              "       dtype=float32),\n",
              " array([ 0.7060961 ,  0.29118517,  0.25384128,  0.08627348, -0.08838722,\n",
              "         0.4370995 ,  0.4452707 ,  0.4714939 ,  0.5909117 , -0.20125407,\n",
              "         0.09093236, -0.5421501 , -0.36399522,  0.24459796,  0.12113892,\n",
              "        -0.12675866,  0.40696403,  0.66138715,  0.50871265, -0.17878531,\n",
              "         0.7585348 ,  0.33445   ,  0.51620185,  0.78404385,  0.2070577 ,\n",
              "         0.27138138,  0.04251205, -0.2798836 ,  0.06614223,  0.6534547 ,\n",
              "        -0.01607295,  0.07139298,  0.26668927,  0.05462629,  0.17297867,\n",
              "         0.38718203,  0.19774018,  0.49936342,  0.6312844 ,  0.22538018,\n",
              "         0.3260198 ,  0.29869908,  0.30433345,  0.7634811 , -0.19084309,\n",
              "         0.53565377,  0.17591876,  0.06336191,  0.51610535,  0.09458559,\n",
              "         0.61678755,  0.24934025,  0.6809879 ,  0.12594189,  0.22049968,\n",
              "        -0.19341122,  0.09255411,  0.12941167,  0.30290052,  0.14660905,\n",
              "        -0.00343758,  0.20616734,  0.57876533,  0.15412213], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfujPZsuet6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}